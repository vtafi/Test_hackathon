const { GoogleGenerativeAI } = require("@google/generative-ai");
const https = require("https");
const http = require("http");

class GeminiClient {
  constructor() {
    this.apiKey = process.env.GEMINI_API_KEY;
    this.genAI = null;

    // TƒÉng timeout cho HTTP requests
    https.globalAgent.options.timeout = 30000;
    http.globalAgent.options.timeout = 30000;
  }

  /**
   * Kh·ªüi t·∫°o Gemini AI
   */
  initialize() {
    if (!this.apiKey) {
      throw new Error("GEMINI_API_KEY ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh trong .env");
    }

    if (!this.genAI) {
      this.genAI = new GoogleGenerativeAI(this.apiKey);
      console.log("‚úÖ Gemini AI kh·ªüi t·∫°o th√†nh c√¥ng");
    }

    return this.genAI;
  }

  /**
   * Retry helper with exponential backoff
   */
  async retryWithBackoff(fn, maxRetries = 3, initialDelay = 1000) {
    for (let i = 0; i < maxRetries; i++) {
      try {
        return await fn();
      } catch (error) {
        if (i === maxRetries - 1) throw error;

        const delay = initialDelay * Math.pow(2, i);
        console.log(`‚è≥ Retry ${i + 1}/${maxRetries} after ${delay}ms...`);
        await new Promise((resolve) => setTimeout(resolve, delay));
      }
    }
  }

  /**
   * T·∫°o c·∫£nh b√°o ng·∫≠p l·ª•t b·∫±ng AI
   */
  async generateFloodAlert(alertData) {
    const genAI = this.initialize();

    return this.retryWithBackoff(
      async () => {
        try {
          const {
            current_percent,
            previous_percent,
            location,
            timestamp,
            water_level_cm,
            flood_status,
          } = alertData;

          // T·∫°o prompt chi ti·∫øt
          const prompt = `
B·∫°n l√† m·ªôt h·ªá th·ªëng Tr√≠ tu·ªá Nh√¢n t·∫°o chuy√™n bi·ªát trong vi·ªác t·∫°o ra c√°c th√¥ng b√°o c·∫£nh b√°o ng·∫≠p l·ª•t kh·∫©n c·∫•p, c√≥ t√≠nh h√†nh ƒë·ªông.

D·ªØ li·ªáu quan tr·∫Øc m·ªõi nh·∫•t:
${location ? `- V·ªã tr√≠ Tr·∫°m: ${location}` : ""}
${current_percent ? `- M·ª©c ng·∫≠p HI·ªÜN T·∫†I: ${current_percent}%` : ""}
${previous_percent ? `- M·ª©c ng·∫≠p tr∆∞·ªõc ƒë√≥ 5 ph√∫t: ${previous_percent}%` : ""}
${water_level_cm ? `- M·ª©c n∆∞·ªõc hi·ªán t·∫°i: ${water_level_cm} cm` : ""}
${flood_status ? `- Tr·∫°ng th√°i: ${flood_status}` : ""}
- Ng∆∞·ª°ng Nguy hi·ªÉm Cao (ƒê·ªè): 80%
- Ng∆∞·ª°ng C·∫£nh b√°o Trung b√¨nh (V√†ng): 60%
- Th·ªùi ƒëi·ªÉm ƒëo: ${timestamp || new Date().toLocaleString("vi-VN")}

Y√äU C·∫¶U ƒê·∫¶U RA:
1. X√°c ƒë·ªãnh C·∫§P ƒê·ªò NGUY HI·ªÇM (Th·∫•p/Trung b√¨nh/Cao) v√† T·ªêC ƒê·ªò N∆∞·ªõc TƒÇNG (Nhanh/Ch·∫≠m/·ªîn ƒë·ªãnh).
2. N·ªôi dung Email (Body): D∆∞·ªõi 150 t·ª´, s·ª≠ d·ª•ng ng√¥n ng·ªØ kh·∫©n c·∫•p, c√≥ c·∫•u tr√∫c **HTML ƒë∆°n gi·∫£n** (d√πng <b>, <br>, <ul>, <li>), v√† **KH√îNG D√ôNG Markdown**.
3. ƒê∆∞a ra **H√ÄNH ƒê·ªòNG C·ª§ TH·ªÇ** theo c·∫•p ƒë·ªô nguy hi·ªÉm (v√≠ d·ª•: Di d·ªùi t√†i s·∫£n, Tr√°nh tuy·∫øn ƒë∆∞·ªùng).
4. H√£y s·ª≠ d·ª•ng ti·∫øng Vi·ªát chu·∫©n.

FORMAT B·∫ÆT BU·ªòC: Tr·∫£ v·ªÅ **DUY NH·∫§T** m·ªôt ƒë·ªëi t∆∞·ª£ng JSON v·ªõi 2 tr∆∞·ªùng: subject v√† htmlBody.

Tr·∫£ v·ªÅ ƒê√öNG format JSON n√†y (kh√¥ng c√≥ markdown, kh√¥ng c√≥ \`\`\`json):
{
  "subject": "ti√™u ƒë·ªÅ email",
  "htmlBody": "n·ªôi dung HTML"
}
`;

          const model = genAI.getGenerativeModel({
            model: "gemini-2.5-flash",
          });

          const result = await model.generateContent(prompt, {
            timeout: 30000, // 30 seconds timeout
          });
          const response = await result.response;
          let text = response.text();

          console.log("üìù Raw Gemini response:", text);

          // Parse JSON t·ª´ response
          let generatedAlert;
          try {
            // Lo·∫°i b·ªè markdown code blocks n·∫øu c√≥
            const jsonMatch =
              text.match(/```json\n?([\s\S]*?)\n?```/) ||
              text.match(/```\n?([\s\S]*?)\n?```/);

            if (jsonMatch) {
              text = jsonMatch[1];
            }

            // Clean text: lo·∫°i b·ªè comments, trailing commas, v√† whitespace th·ª´a
            text = text
              .replace(/\/\/.*/g, "") // Lo·∫°i b·ªè // comments
              .replace(/\/\*[\s\S]*?\*\//g, "") // Lo·∫°i b·ªè /* */ comments
              .replace(/,(\s*[}\]])/g, "$1") // Lo·∫°i b·ªè trailing commas
              .trim();

            generatedAlert = JSON.parse(text);
          } catch (e) {
            console.error("‚ùå JSON parse error:", e.message);
            console.error("üìÑ Text to parse:", text);
            throw new Error(
              `Kh√¥ng th·ªÉ parse JSON t·ª´ Gemini response: ${e.message}`
            );
          }

          console.log("‚úÖ Gemini AI ƒë√£ t·∫°o c·∫£nh b√°o:", generatedAlert.subject);
          return generatedAlert;
        } catch (error) {
          console.error("‚ùå L·ªói g·ªçi Gemini API:", error.message);
          throw error;
        }
      },
      3,
      2000
    ); // 3 retries, starting with 2s delay
  }

  /**
   * T·∫°o ph√¢n t√≠ch th·ªùi ti·∫øt b·∫±ng AI
   */
  async analyzeWeatherData(weatherData) {
    const genAI = this.initialize();

    return this.retryWithBackoff(
      async () => {
        try {
          const prompt = `
Ph√¢n t√≠ch d·ªØ li·ªáu th·ªùi ti·∫øt sau v√† ƒë∆∞a ra c·∫£nh b√°o n·∫øu c·∫ßn:

${JSON.stringify(weatherData, null, 2)}

Tr·∫£ v·ªÅ JSON v·ªõi format:
{
  "severity": "low|medium|high",
  "summary": "T√≥m t·∫Øt ng·∫Øn g·ªçn",
  "recommendations": ["Khuy·∫øn ngh·ªã 1", "Khuy·∫øn ngh·ªã 2"]
}
`;

          const model = genAI.getGenerativeModel({
            model: "gemini-2.5-flash",
          });

          const result = await model.generateContent(prompt);
          const response = await result.response;
          const text = response.text();

          // Parse JSON
          const jsonMatch = text.match(/\{[\s\S]*\}/);
          if (jsonMatch) {
            return JSON.parse(jsonMatch[0]);
          }

          throw new Error("Kh√¥ng th·ªÉ parse JSON t·ª´ response");
        } catch (error) {
          console.error("‚ùå L·ªói ph√¢n t√≠ch th·ªùi ti·∫øt:", error.message);
          throw error;
        }
      },
      3,
      2000
    ); // 3 retries, starting with 2s delay
  }

  /**
   * T·∫°o n·ªôi dung c√≥ c·∫•u tr√∫c v·ªõi JSON schema
   * @param {string} prompt - Prompt cho AI
   * @param {object} schema - JSON schema cho response
   */
  async generateStructuredContent(prompt, schema) {
    const genAI = this.initialize();

    return this.retryWithBackoff(
      async () => {
        try {
          const model = genAI.getGenerativeModel({
            model: "gemini-2.5-flash",
            generationConfig: {
              responseMimeType: "application/json",
              responseSchema: schema,
            },
          });

          const result = await model.generateContent(prompt, {
            timeout: 30000,
          });
          const response = await result.response;
          const text = response.text();

          // Parse JSON
          return JSON.parse(text);
        } catch (error) {
          console.error("‚ùå L·ªói generate structured content:", error.message);
          throw error;
        }
      },
      3,
      2000
    );
  }
}

module.exports = new GeminiClient();
